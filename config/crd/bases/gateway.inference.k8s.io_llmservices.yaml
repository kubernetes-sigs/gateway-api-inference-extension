---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.16.1
  name: llmservices.gateway.inference.k8s.io
spec:
  group: gateway.inference.k8s.io
  names:
    kind: LLMService
    listKind: LLMServiceList
    plural: llmservices
    singular: llmservice
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: LLMService is the Schema for the llmservices API
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: |-
              LLMService represents a set of LLM services that are multiplexed onto one
              or more backend pools. This resource is managed by the "LLM Service Owner"
              persona. The Service Owner persona is: a team that trains, verifies, and
              leverages a large language model from a model frontend, drives the lifecycle
              and rollout of new versions of those models, and defines the specific
              performance and latency goals for the model. These services are
              expected to operate within a LLMServerPool sharing compute capacity with other
              LLMServices, defined by the Inference Platform Admin. We allow a user who
              has multiple LLMServices across multiple pools (with the same config) to
              specify the configuration exactly once, and deploy to many pools
              simultaneously. Enabling a simpler config and single source of truth
              for a given user. LLMService names are unique for a given LLMServerPool,
              if the name is reused, an error will be  shown on the status of a
              LLMService that attempted to reuse. The oldest LLMService, based on
              creation timestamp, will be selected to remain valid. In the event of a race
              condition, one will be selected at random.
            type: object
          status:
            description: LLMServiceStatus defines the observed state of LLMService
            properties:
              conditions:
                description: Conditions track the state of the LLMServerPool.
                items:
                  description: Condition contains details for one aspect of the current
                    state of this API Resource.
                  properties:
                    lastTransitionTime:
                      description: |-
                        lastTransitionTime is the last time the condition transitioned from one status to another.
                        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: |-
                        message is a human readable message indicating details about the transition.
                        This may be an empty string.
                      maxLength: 32768
                      type: string
                    observedGeneration:
                      description: |-
                        observedGeneration represents the .metadata.generation that the condition was set based upon.
                        For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
                        with respect to the current state of the instance.
                      format: int64
                      minimum: 0
                      type: integer
                    reason:
                      description: |-
                        reason contains a programmatic identifier indicating the reason for the condition's last transition.
                        Producers of specific condition types may define expected values and meanings for this field,
                        and whether the values are considered a guaranteed API.
                        The value should be a CamelCase string.
                        This field may not be empty.
                      maxLength: 1024
                      minLength: 1
                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                      type: string
                    status:
                      description: status of the condition, one of True, False, Unknown.
                      enum:
                      - "True"
                      - "False"
                      - Unknown
                      type: string
                    type:
                      description: type of condition in CamelCase or in foo.example.com/CamelCase.
                      maxLength: 316
                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                type: array
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
