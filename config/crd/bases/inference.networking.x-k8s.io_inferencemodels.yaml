---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.16.1
  name: inferencemodels.inference.networking.x-k8s.io
spec:
  group: inference.networking.x-k8s.io
  names:
    kind: InferenceModel
    listKind: InferenceModelList
    plural: inferencemodels
    singular: inferencemodel
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .spec.modelName
      name: ModelName
      type: string
    - jsonPath: .status.conditions[?(@.type=="Accepted")].status
      name: Accepted
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1alpha1
    schema:
      openAPIV3Schema:
        description: |-
          InferenceModel is the Schema for the InferenceModels API.
          The InferenceModel is intended to represent a model workload (also referred to as a model use case) within Kubernetes.
          The management of the model server is not done by the InferenceModel. Instead, the
          focus of the InferenceModel is to provide the tools needed to effectively manage multiple models
          that share the same base model (currently the focus is LoRA adapters). Fields such as TargetModel
          are intended to simplify A/B testing and version rollout of adapters. While Criticality assists with
          governance of multiplexing many usecases over shared hardware.
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: |-
              InferenceModelSpec represents the desired state of an InferenceModel. This resource is
              managed by the "Inference Workload Owner" persona.

              The Inference Workload Owner persona is someone that trains, verifies, and
              leverages a large language model focusing on model fidelity performance, and
              less on inference performance (which is managed by the Inference Platform Admin).
              They also drive the lifecycle and rollout of new versions of those models, and defines the specific
              performance and latency goals for the model. These workloads are
              expected to operate within an InferencePool sharing compute capacity with other
              InferenceModels, with specific governance defined by the Inference Platform Admin.
            properties:
              criticality:
                description: |-
                  Criticality defines how important it is to serve the model compared to other models referencing the same pool.
                  Criticality impacts how traffic is handled in resource constrained situations. It handles this by
                  queuing or rejecting requests of lower criticality. InferenceModels of an equivalent Criticality will
                  fairly share resources over throughput of tokens. In the future, the metric used to calculate fairness,
                  and the proportionality of fairness will be configurable.

                  Default values for this field will not be set, to allow for future additions of new field that may 'one of' with this field.
                  Any implementations that may consume this field may treat an unset value as the 'Standard' range.
                enum:
                - Critical
                - Standard
                - Sheddable
                type: string
              modelName:
                description: |-
                  ModelName is the name of the model as the users set in the "model" parameter in the requests.
                  The name should be unique among the workloads that reference the same backend pool.
                  This is the parameter that will be used to match the request with.
                  Names can be reserved without implementing an actual model in the pool.
                  This can be done by specifying a target model and setting the weight to zero,
                  an error will be returned specifying that no valid target model is found.
                maxLength: 256
                type: string
              poolRef:
                description: PoolRef is a reference to the inference pool, the pool
                  must exist in the same namespace.
                properties:
                  group:
                    default: inference.networking.x-k8s.io
                    description: Group is the group of the referent.
                    maxLength: 253
                    pattern: ^$|^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$
                    type: string
                  kind:
                    default: InferencePool
                    description: Kind is kind of the referent. For example "InferencePool".
                    maxLength: 63
                    minLength: 1
                    pattern: ^[a-zA-Z]([-a-zA-Z0-9]*[a-zA-Z0-9])?$
                    type: string
                  name:
                    description: Name is the name of the referent.
                    maxLength: 253
                    minLength: 1
                    type: string
                required:
                - name
                type: object
              targetModels:
                description: |-
                  TargetModels allow multiple versions of a model for traffic splitting.
                  Traffic splitting is handled via weights. The targetModel field is optional, however,
                  if not specified, the target model name is defaulted to the modelName parameter.
                  modelName is often in reference to a LoRA adapter.

                  Examples:
                  - A model server serving `llama2-7b` may be represented by:
                    - setting the modelName to `llama2-7b` and setting no targetModels
                    - setting the modelName to `hello-world` and setting a single targetModel to `llama2-7b`, and setting no weights
                    - setting modelName to 'my-fine-tune' setting 2 targetModels 'fine-tune-v1' & 'fine-tune-v2' and setting no weights.
                        This has the effect of weighing the two models equally
                    - setting modelName to 'my-fine-tune' setting 2 targetModels 'fine-tune-v1' w/weight: 10 & 'fine-tune-v2' w/weight: 1.
                        This has the effect of the fine-tune-v1 being selected 10x as often as v2
                items:
                  description: |-
                    TargetModel represents a deployed model or a LoRA adapter. The
                    Name field is expected to match the name of the LoRA adapter
                    (or base model) as it is registered within the model server. Inference
                    Gateway assumes that the model exists on the model server and it's the
                    responsibility of the user to validate a correct match. Should a model fail
                    to exist at request time, the error is processed by the Inference Gateway
                    and emitted on the appropriate InferenceModel object.
                  properties:
                    name:
                      description: Name is the name of the LoRA adapter or base model,
                        as expected by the ModelServer.
                      maxLength: 253
                      type: string
                    weight:
                      description: |-
                        Weight is used to determine the proportion of traffic that should be
                        sent to this model when multiple target models are specified.

                        Weight defines the proportion of requests forwarded to the specified
                        model. This is computed as weight/(sum of all weights in this
                        TargetModels list). For non-zero values, there may be some epsilon from
                        the exact proportion defined here depending on the precision an
                        implementation supports. Weight is not a percentage and the sum of
                        weights does not need to equal 100.

                        If a weight is set for any targetModel, it must be set for all targetModels.
                        Conversely weights are optional, so long as ALL targetModels do not specify a weight.
                      format: int32
                      maximum: 1000000
                      minimum: 0
                      type: integer
                  required:
                  - name
                  type: object
                maxItems: 10
                type: array
                x-kubernetes-validations:
                - message: Weights should be set for all models, or none of the models.
                  rule: self.all(model, has(model.weight)) || self.all(model, !has(model.weight))
            required:
            - modelName
            - poolRef
            type: object
          status:
            description: InferenceModelStatus defines the observed state of InferenceModel
            properties:
              conditions:
                default:
                - lastTransitionTime: "1970-01-01T00:00:00Z"
                  message: Waiting for controller
                  reason: Pending
                  status: Unknown
                  type: Ready
                description: |-
                  Conditions track the state of the InferenceModel.

                  Known condition types are:

                  * "Accepted"
                items:
                  description: Condition contains details for one aspect of the current
                    state of this API Resource.
                  properties:
                    lastTransitionTime:
                      description: |-
                        lastTransitionTime is the last time the condition transitioned from one status to another.
                        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: |-
                        message is a human readable message indicating details about the transition.
                        This may be an empty string.
                      maxLength: 32768
                      type: string
                    observedGeneration:
                      description: |-
                        observedGeneration represents the .metadata.generation that the condition was set based upon.
                        For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
                        with respect to the current state of the instance.
                      format: int64
                      minimum: 0
                      type: integer
                    reason:
                      description: |-
                        reason contains a programmatic identifier indicating the reason for the condition's last transition.
                        Producers of specific condition types may define expected values and meanings for this field,
                        and whether the values are considered a guaranteed API.
                        The value should be a CamelCase string.
                        This field may not be empty.
                      maxLength: 1024
                      minLength: 1
                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                      type: string
                    status:
                      description: status of the condition, one of True, False, Unknown.
                      enum:
                      - "True"
                      - "False"
                      - Unknown
                      type: string
                    type:
                      description: type of condition in CamelCase or in foo.example.com/CamelCase.
                      maxLength: 316
                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                maxItems: 8
                type: array
                x-kubernetes-list-map-keys:
                - type
                x-kubernetes-list-type: map
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
