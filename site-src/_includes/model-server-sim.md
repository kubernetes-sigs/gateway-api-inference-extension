=== "vLLM Simulator Model Server"

    This option uses the [vLLM simulator](https://github.com/llm-d/llm-d-inference-sim/tree/main) to simulate a backend model server.
    This setup uses the least amount of compute resources, does not require GPU's, and is ideal for test/dev environments.

    To deploy the vLLM simulator, run the following command.
