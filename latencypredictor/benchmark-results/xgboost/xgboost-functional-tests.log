============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0 -- /usr/local/bin/python3.11
cachedir: .pytest_cache
rootdir: /app
plugins: anyio-4.12.1, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 29 items / 3 deselected / 26 selected

test/test_dual_server_client.py::test_prediction_server_healthz Waiting for prediction server...
Waiting for training server...
PASSED
test/test_dual_server_client.py::test_training_server_healthz PASSED
test/test_dual_server_client.py::test_prediction_server_readyz PASSED
test/test_dual_server_client.py::test_training_server_readyz PASSED
test/test_dual_server_client.py::test_prediction_server_status Prediction server using model type: xgboost
Models exist: {'ttft_model': True, 'tpot_model': True}
Quantile: 0.9
Models ready: True
PASSED
test/test_dual_server_client.py::test_training_server_model_info Training server using model type: xgboost
PASSED
test/test_dual_server_client.py::test_training_server_models_list Model ttft: exists=True, size=143390 bytes
Model tpot: exists=True, size=142823 bytes
PASSED
test/test_dual_server_client.py::test_model_download_from_training_server Successfully downloaded ttft model (143390 bytes)
Successfully downloaded tpot model (142823 bytes)
PASSED
test/test_dual_server_client.py::test_treelite_models_on_training_server SKIPPED
test/test_dual_server_client.py::test_add_training_data_to_training_server Successfully sent training data to training server
  Cleaned up test data: Successfully flushed: 44 TTFT and 44 TPOT training samples, 6 TTFT and 6 TPOT test samples, all metric scores
PASSED
test/test_dual_server_client.py::test_prediction_server_model_sync Flushing old training data...
  ✓ Training data flushed: Successfully flushed: 0 TTFT and 0 TPOT training samples, 0 TTFT and 0 TPOT test samples, all metric scores
Adding 150 training samples...
✓ Added 150 training samples
Waiting for bundle with ≥108 TTFT and ≥108 TPOT samples (timeout: 32s)...
  Waiting... current: TTFT=0, TPOT=0 (need: ≥108, ≥108)
  ✓ Bundle found after 4s: TTFT=134, TPOT=134 samples
✓ Prediction server models are trained! (TTFT: 134, TPOT: 134 samples)
  ✓ Training data flushed: Successfully flushed: 134 TTFT and 134 TPOT training samples, 16 TTFT and 16 TPOT test samples, all metric scores
PASSED
test/test_dual_server_client.py::test_prediction_endpoint_response_format ✓ Prediction using TRAINED models: TTFT=10.00ms, TPOT=10.00ms
  Trained on 134 TTFT samples, 134 TPOT samples
  Model type: xgboost
PASSED
test/test_dual_server_client.py::test_bulk_prediction_strict Testing bulk prediction strict endpoint...
✓ Bulk prediction strict endpoint test passed
PASSED
test/test_dual_server_client.py::test_bulk_prediction_with_validation_errors Testing bulk prediction validation error handling...
✓ Bulk prediction correctly failed when any request had validation errors
PASSED
test/test_dual_server_client.py::test_bulk_prediction_all_valid Testing bulk prediction with all valid requests...
✓ Bulk prediction succeeded with all valid requests
PASSED
test/test_dual_server_client.py::test_prediction_missing_prefix_cache_score ✓ Prediction correctly failed when prefix_cache_score was missing
PASSED
test/test_dual_server_client.py::test_training_server_metrics Training server metrics endpoint working correctly
✓ Prefix cache score feature found in metrics
PASSED
test/test_dual_server_client.py::test_model_consistency_between_servers Model type consistent across servers: xgboost
PASSED
test/test_dual_server_client.py::test_model_specific_endpoints_on_training_server Testing XGBoost tree endpoints on training server...
✓ TTFT XGBoost trees available: 200 trees
✓ TPOT XGBoost trees available: 200 trees
PASSED
test/test_dual_server_client.py::test_dual_server_quantile_regression_learns_distribution Using random seed: 18051
Flushing old training data...
  ✓ Training data flushed: Successfully flushed: 0 TTFT and 0 TPOT training samples, 0 TTFT and 0 TPOT test samples, all metric scores
Expected calibration samples: 500 (min threshold: 400)
Detected mode: native quantile (coverage tolerance: ±5.0%)
Submitting 5000 training samples...
  Attempt 1: POSTing 5000 entries to http://training-service:8000/add_training_data_bulk
  Response: 202 - {'message': 'Accepted 5000 training samples.'}
✓ Training data submitted successfully after 1 attempt(s)
Expected training samples: 4500 (min threshold: 3600)
Waiting for bundle with ≥3600 TTFT and ≥3600 TPOT samples (timeout: 32s)...
  Waiting... current: TTFT=134, TPOT=134 (need: ≥3600, ≥3600)
  ✓ Bundle found after 5s: TTFT=4525, TPOT=4525 samples
Flushing training data to stabilize bundle for pod sync...
  ✓ Training data flushed: Successfully flushed: 4525 TTFT and 4525 TPOT training samples, 475 TTFT and 475 TPOT test samples, all metric scores
Waiting for all prediction server pods to sync good native quantile models...
  Attempt 1: Pods have different bundles: {'3567ff16', 'b185cfc4', 'e7924177', '7124f987', '7e96ff82'}
✓ All pods synced after 5 seconds (bundle: e7924177)
  TTFT: input_len=100: 535.92ms, 400: 973.79ms, 600: 1406.85ms (std: 355.56)
  TPOT: input_len=100: 161.96ms, 400: 285.73ms, 600: 390.97ms (std: 93.59)
Skipping calibration data verification (native quantile mode doesn't need conformal prediction)
Relative-err accuracy (≤15%): 86.2%
Coverage: TTFT=0.908, TPOT=0.870 (target 0.900 ± 0.05)
PASSED
test/test_dual_server_client.py::test_end_to_end_workflow Testing end-to-end workflow...
Step 1: Sending training data to training server...
Step 2: Waiting for training...
Step 3: Syncing models to prediction server...
Step 4: Making predictions...
  Prediction 1: TTFT=1797.61ms, TPOT=512.31ms (prefix_cache=0.38)
  Prediction 2: TTFT=1860.08ms, TPOT=512.31ms (prefix_cache=0.80)
  Prediction 3: TTFT=1860.08ms, TPOT=512.31ms (prefix_cache=0.11)
  Prediction 4: TTFT=1860.08ms, TPOT=512.31ms (prefix_cache=0.53)
  Prediction 5: TTFT=1746.30ms, TPOT=501.52ms (prefix_cache=0.95)
✓ End-to-end workflow completed successfully!
  ✓ Training data flushed: Successfully flushed: 17 TTFT and 17 TPOT training samples, 3 TTFT and 3 TPOT test samples, all metric scores
PASSED
test/test_dual_server_client.py::test_server_configuration Testing server configuration...
Prediction server: HTTP-based Quantile Latency Predictor is running
  Model type: xgboost
  Is ready: True
  Sync interval: 10s
  Training server URL: http://training-service:8000
Training server: Latency Predictor is running.
  Model type: xgboost
PASSED
test/test_dual_server_client.py::test_training_server_flush_api Testing training server flush API...
Step 1: Checking initial data status...
  Initial training samples: TTFT=0, TPOT=0
  Initial test samples: TTFT=0, TPOT=0
Step 2: Adding training data...
  Added 100 training samples
Step 3: Verifying data was added...
  After adding - Training: 178, Test: 22, Total: 200
Step 4: Testing flush with only training data...
  Flushed 89 TTFT training samples
  Flushed 89 TPOT training samples
  Test samples flushed: 0 TTFT, 0 TPOT (should be 0)
  After training flush - Training: 0, Test: 22
Step 5: Adding more training data...
Step 6: Testing flush everything...
  Complete flush message: Successfully flushed: 42 TTFT and 42 TPOT training samples, 19 TTFT and 19 TPOT test samples, all metric scores
  After complete flush - Training: 0, Test: 0
Step 7: Testing default flush (no body)...
  Default flush result: Successfully flushed: 19 TTFT and 19 TPOT training samples, 1 TTFT and 1 TPOT test samples, all metric scores
Step 8: Testing flush with only test data...
  Test data flush: 6 TTFT, 6 TPOT
  After test flush - Training: 88, Test: 0
Step 9: Testing bucket distribution in status...
  Bucket distribution available: 0 buckets with data
✓ Flush API tests passed!
PASSED
test/test_dual_server_client.py::test_training_server_flush_error_handling Testing flush API error handling...
✓ Invalid JSON handled correctly
✓ Flush error handling tests passed!
PASSED
test/test_dual_server_client.py::test_native_quantile_mode 
==================================================
Testing Native Quantile Mode (USE_TREELITE=false)
==================================================
Step 1: Checking server configuration...
  Model type: xgboost
  Quantile: 0.9
Step 2: Verifying TreeLite models are NOT created...
  ✓ TreeLite models NOT created (as expected in native quantile mode)
Step 3: Sending training data...
  ✓ Sent 5000 training samples
Step 4: Waiting for training to complete...
Waiting for 2 training cycles to complete...
  Initial last_load timestamp: 2026-01-18T01:10:52.371718Z
  ✓ Cycle 1/2 completed after 1s (synced: True)
  ✓ Cycle 2/2 completed after 1s (synced: True)
✓ All 2 training cycles completed
Flushing training data to stabilize bundle for pod sync...
  ✓ Training data flushed: Successfully flushed: 4550 TTFT and 4550 TPOT training samples, 494 TTFT and 494 TPOT test samples, all metric scores
Step 5: Syncing models to prediction server...
Waiting for all prediction server pods to sync good native quantile models...
  Attempt 1: Predictions not monotonic (TTFT: True, TPOT: False) - waiting for good models...
✓ All pods synced after 6 seconds (bundle: 09857e7e)
  TTFT: input_len=100: 561.79ms, 400: 1134.97ms, 600: 1418.27ms (std: 356.27)
  TPOT: input_len=100: 161.12ms, 400: 312.44ms, 600: 386.54ms (std: 93.81)
Step 6: Testing predictions and coverage...
  Coverage: TTFT=88.0%, TPOT=89.0% (target: 90%)
✓ Native quantile mode test passed!
  ✓ Training data flushed: Successfully flushed: 0 TTFT and 0 TPOT training samples, 0 TTFT and 0 TPOT test samples, all metric scores
PASSED
test/test_dual_server_client.py::test_treelite_conformal_mode 
==================================================
Testing TreeLite + Conformal Mode (USE_TREELITE=true)
==================================================
SKIPPED

================= 24 passed, 2 skipped, 3 deselected in 55.93s =================
