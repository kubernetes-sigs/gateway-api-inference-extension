apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: LLMService
metadata:
  labels:
    app.kubernetes.io/name: api
    app.kubernetes.io/managed-by: kustomize
  name: llmservice-sample
spec:
  models:
  - name: sql-code-assist
  - name: npc-bot
    objective: 
      desiredAveragePerOutputTokenLatencyAtP95OverMultipleRequests: 50
    targetModels:
    - name: npc-bot-v1
      weight: 50
    - name: npc-bot-v2
      weight: 50 	
  poolRef:
  - kind: LLMServerPool
    name: test-pool
  - name: gemini-pool
    kind: LLMServerPool