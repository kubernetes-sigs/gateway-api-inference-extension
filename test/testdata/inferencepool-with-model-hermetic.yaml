apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferencePool
metadata:
  name: vllm-llama2-7b-pool
  namespace: default
spec:
  targetPortNumber: 8000
  selector:
    app: vllm-llama2-7b-pool
  extensionRef:
    name: epp
---
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceModel
metadata:
  name: inferencemodel-sample
  namespace: default
spec:
  modelName: sql-lora
  criticality: Critical
  poolRef:
    name: vllm-llama2-7b-pool
  targetModels:
  - name: sql-lora-1fdg2
    weight: 100
---
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceModel
metadata:
  name: inferencemodel-sheddable
  namespace: default
spec:
  modelName: sql-lora-sheddable
  poolRef:
    name: vllm-llama2-7b-pool
  targetModels:
  - name: sql-lora-1fdg3
    weight: 100
---
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceModel
metadata:
  name: inferencemodel-generic
  namespace: default
spec:
  modelName: my-model
  criticality: Critical
  poolRef:
    name: vllm-llama2-7b-pool
  targetModels:
  - name: my-model-12345
    weight: 100    
