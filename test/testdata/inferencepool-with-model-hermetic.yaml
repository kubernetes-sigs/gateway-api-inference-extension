apiVersion: inference.networking.k8s.io/v1
kind: InferencePool
metadata:
  name: vllm-llama3-8b-instruct-pool
  namespace: default
spec:
  targetPorts:
    - number: 8000
  selector:
    matchLabels:
      app: vllm-llama3-8b-instruct-pool
  endpointPickerRef:
    name: epp
    kind: Service
    port:
      number: 9002
---
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceObjective
metadata:
  name: sql-lora
  namespace: default
spec:
  priority: 2
  poolRef:
    name: vllm-llama3-8b-instruct-pool
  targetModels:
  - name: sql-lora-1fdg2
    weight: 100
---
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceObjective
metadata:
  name: sql-lora-sheddable
  namespace: default
spec:
  poolRef:
    name: vllm-llama3-8b-instruct-pool
  targetModels:
  - name: sql-lora-1fdg3
    weight: 100
---
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceObjective
metadata:
  name: my-model
  namespace: default
spec:
  priority: 2
  poolRef:
    name: vllm-llama3-8b-instruct-pool
  targetModels:
  - name: my-model-12345
    weight: 100    
---
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceObjective
metadata:
  name: direct-model
  namespace: default
spec:
  priority: 2
  poolRef:
    name: vllm-llama3-8b-instruct-pool
